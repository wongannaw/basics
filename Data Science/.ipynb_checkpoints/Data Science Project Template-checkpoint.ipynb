{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project Template\n",
    "\n",
    "Adapted from 36-462: Data Mining S17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "- Importing data and libraries\n",
    "- Figuring out what the data is: variable types, distribution, relationships\n",
    "- Looking for problems: outliers, missing data, inconsistent coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries, more imports below as needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import/load data \n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "- Dimension of the data, variable, observations\n",
    "- Variable types: factors, dates, numeric\n",
    "- Variable distributions: Number of factor levels, imbalance of factor levels, skewness of variables. Base rate and balance of outcome\n",
    "- Simple relationships between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data\n",
    "\n",
    "Can help to inform modeling and feature extraction\n",
    "\n",
    "- Plot univariate and bivariate distributions of variables- are they continuous? Bumpy? Mixed?\n",
    "- Look at conditional plots and investigate differences\n",
    "- Is there temporal or spatial structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the outcome of interest?\n",
    "\n",
    "Is is a continuous regression problem?\n",
    "- Do we care what the value is? Or if it just large?\n",
    "- How does the variable behave? Heavily skewed? Are there many big values we care about?\n",
    "\n",
    "Is is a classification problem?\n",
    "- How many classes are there?\n",
    "- What are the default class proportions? What is the base rate? Is there severe imbalance?\n",
    "    - Do we want better misclassification, or just enriched subsets of the data?\n",
    "    - Are your costs asymmetric enough that you should be thinking about different cutoffs? (Sensitivity, specificity, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints on the classifier\n",
    "\n",
    "- Is training time severely limited (pretty rare)\n",
    "- Is evaluation/prediction time severely limited? (Very common)\n",
    "- Limits to types of variables to use\n",
    "- Does the model need to be interpretable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Worry about points abnormal enough that they unduly influence the model. These may be:\n",
    "\n",
    "- Mistakes\n",
    "- Observations that are not coming from the process we want to model\n",
    "\n",
    "Outliers can be identified in plots, or by a variety of rules (large Mahalanobis distance, high leverage, etc). Sometimes they are fixable, other times just missing\n",
    "\n",
    "## Missing data\n",
    "\n",
    "- Remove whole observations if the missingness is not informative, this only costs data. If it is informative, losing information biases the population.\n",
    "- Try to fill in the missing values: imputation\n",
    "\n",
    "    1). Use a strongly correlated variable to predict the missing values\n",
    "    \n",
    "    2). Nearest neighbors: find the k closest other points and average their value for this entry\n",
    "    \n",
    "- Can code missing value as another value (sometimes)\n",
    "- Use a method that is robust to missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting for badly imbalanced data\n",
    "\n",
    "Suppose the data is 90% class 1 and 10% class 2\n",
    "\n",
    "- Downsample: Sample one (or a few) elements of class 1 for each element of class 2 to make more balanced\n",
    "- Upsampling: Duplicate elements of class 2 to make more balanced\n",
    "- Artificially change prior weights, class weights, or case weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# downsample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start learning\n",
    "\n",
    "### Validation: Plan workflow from the start\n",
    "\n",
    "Validation plan:\n",
    "\n",
    "1). Split the data into a training set and test set [(basic train test split)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) [(stratified splitting)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n",
    "\n",
    "2). Do all model selection and experimentation on the training set. Use [cross validation](https://scikit-learn.org/0.16/modules/generated/sklearn.cross_validation.train_test_split.html) or out-of-bag errors only on this set to pick a model\n",
    "\n",
    "3). Fit chose model on the whole training set\n",
    "\n",
    "4). At the very end, use your testing set to get an accurate picture of how well the model actually performs\n",
    "\n",
    "5). For production, fit model on the whole dataset\n",
    "\n",
    "### Warnings about cross-validation\n",
    "\n",
    "1). Can have a high computational cost, especially as the number of parameters/models grows\n",
    "\n",
    "2). When the number of models is verty large, it can give misleading results. It is not immune from the usual problems with multiple testing\n",
    "\n",
    "3). The folds need to include the entire estimation pipeline. a frequent mistake is to carry out part of the model selection before breaking the data into folds, which invalidates the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=514)\n",
    "\n",
    "# or, if there are imbalanced classes, might want to use a stratified split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.33, random_state=514)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: Extract reasonable first set of features to use for prediction\n",
    "\n",
    "- With modern model selection algorithms (Lasso, Random Forest) having extra features does not hurt much\n",
    "- Make sure to only use information tbat will be in new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to use: Start with something simple: interpretable, flexible\n",
    "\n",
    "\n",
    "| Model                           | Robust to outliers | Robust to useless variables | Easy to use |\n",
    "|---------------------------------|--------------------|-----------------------------|-------------|\n",
    "| Linear/logistic regression      | &nbsp;             | &nbsp;                      | &nbsp;      |\n",
    "| Ridge regression/logistic ride  | &nbsp;             | &nbsp;                      | &nbsp;      |\n",
    "| Lasso regression/logistic lasso | &nbsp;             | X                           | &nbsp;      |\n",
    "| Splines/additive models         | &nbsp;             | &nbsp;                      | &nbsp;      |\n",
    "| K-nearest neighbors             | X                  | &nbsp;                      | &nbsp;      |\n",
    "| Trees                           | X                  | X                           | &nbsp;      |\n",
    "| Random Forests                  | X                  | X                           | X           |\n",
    "| Boosted trees                   | X                  | X                           | &nbsp;      |\n",
    "| SVM                             | X                  | &nbsp;                      | &nbsp;      |\n",
    "| LDA                             | &nbsp;             | &nbsp;                      | &nbsp;      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Tradeoff\n",
    "\n",
    "- If the training error is much smaller than the test (CV) error, the model is overfit --> lower bias, increase variance\n",
    "- If the training error is about the same as the test (CV) error, the model is not yet overfit --> increase bias, lower variance\n",
    "\n",
    "## Ways to change the model\n",
    "\n",
    "- Get more data: Same bias, decreases variance\n",
    "- Make more/better features: Increase flexibility, increase variance (maybe)\n",
    "- Use a more flexible model: decrease bias\n",
    "- Use a more regularized model: decreases variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning \n",
    "\n",
    "Build _M_ different classifiers, combine guesses by:\n",
    "\n",
    "- Voting, weighted voting\n",
    "- Averaging\n",
    "- Stacking: using guesses as input to another classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
